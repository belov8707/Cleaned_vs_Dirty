{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "cleaned-vs-dirty.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gm0U9oh28LN6"
      },
      "source": [
        "Дан набор данных из 20 чистых и 20 грязных тарелок.\n",
        "\n",
        "Необходимо обучить классификатор определять грязные тарелки.\n",
        "\n",
        "Результат - классифицировать 400 тестовых тарелок."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "plEJ66Eb8HgL"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "\n",
        "import os\n",
        "print(os.listdir(\"../input\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "jm7jEzKF8HgS"
      },
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile('/kaggle/input/platesv2/plates.zip', 'r') as zip_obj:\n",
        "   # Extract all the contents of zip file in current directory\n",
        "   zip_obj.extractall('/kaggle/working/')\n",
        "    \n",
        "print('After zip extraction:')\n",
        "print(os.listdir(\"/kaggle/working/\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "GxXi2FNN8HgT"
      },
      "source": [
        "data_root = '/kaggle/working/plates/'\n",
        "print(os.listdir(data_root))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ip4xsjCW8HgU"
      },
      "source": [
        "#создание 2х новых папок train и val для разделения данных на тренировочные и валидационные. Каждую 6ю фотографию переложим в папку val\n",
        "import shutil \n",
        "from tqdm import tqdm\n",
        "\n",
        "train_dir = 'train'\n",
        "val_dir = 'val'\n",
        "\n",
        "class_names = ['cleaned', 'dirty']\n",
        "\n",
        "for dir_name in [train_dir, val_dir]:\n",
        "    for class_name in class_names:\n",
        "        os.makedirs(os.path.join(dir_name, class_name), exist_ok=True)\n",
        "\n",
        "for class_name in class_names:\n",
        "    source_dir = os.path.join(data_root, 'train', class_name)\n",
        "    for i, file_name in enumerate(tqdm(os.listdir(source_dir))):\n",
        "        if i % 3 != 0:\n",
        "            dest_dir = os.path.join(train_dir, class_name) \n",
        "        else:\n",
        "            dest_dir = os.path.join(val_dir, class_name)\n",
        "        shutil.copy(os.path.join(source_dir, file_name), os.path.join(dest_dir, file_name))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "XvRYVGrV8HgW"
      },
      "source": [
        "!ls train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "AKmF2oBQ8HgW"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import copy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "UFNd9bXv8HgY"
      },
      "source": [
        "#аугментация разными способами, вырезаем часть исходного изображения после чего делаем его размером 224, зеркалим и т.д... \n",
        "# тем самым искуственно увеличиваем количество тренировочных данных для более сильного обучения\n",
        "\n",
        "from torchvision import transforms, models\n",
        "\n",
        "train_transforms_1 = transforms.Compose([\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])  \n",
        "])\n",
        "\n",
        "train_transforms_2 = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "train_transforms_3 = transforms.Compose([\n",
        "    transforms.RandomCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "train_transforms_4 = transforms.Compose([\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "train_transforms_5 = transforms.Compose([\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "train_transforms_6 = transforms.Compose([\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.RandomRotation(degrees=(1,359)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "train_transforms_7 = transforms.Compose([\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ColorJitter(0.6, 0.6, 0.3, 0.3),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "train_transforms_8 = transforms.Compose([\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.RandomGrayscale(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "train_dataset_1 = torchvision.datasets.ImageFolder(train_dir, train_transforms_1)\n",
        "train_dataset_2 = torchvision.datasets.ImageFolder(train_dir, train_transforms_2)\n",
        "train_dataset_3 = torchvision.datasets.ImageFolder(train_dir, train_transforms_3)\n",
        "train_dataset_4 = torchvision.datasets.ImageFolder(train_dir, train_transforms_4)\n",
        "train_dataset_5 = torchvision.datasets.ImageFolder(train_dir, train_transforms_5)\n",
        "train_dataset_6 = torchvision.datasets.ImageFolder(train_dir, train_transforms_6)\n",
        "train_dataset_7 = torchvision.datasets.ImageFolder(train_dir, train_transforms_7)\n",
        "train_dataset_8 = torchvision.datasets.ImageFolder(train_dir, train_transforms_8)\n",
        "\n",
        "train_dataset = torch.utils.data.ConcatDataset([train_dataset_1, train_dataset_2, train_dataset_3, train_dataset_4, train_dataset_5, train_dataset_6, train_dataset_7, train_dataset_8])\n",
        "\n",
        "val_dataset = torchvision.datasets.ImageFolder(val_dir, val_transforms)\n",
        "\n",
        "# ImageFolder при передаче каждого изображения привяжет к нему метку в какой папке он его взял cleaned/dirty (родительской папки)\n",
        "# Чтобы ImageFolder передавал изображения как тензоры, а не как изображения открытые специальной библиотекой PIL, необходимо указывать 2й параметр \"train/val_transforms\", т.е сделать трансформации.\n",
        "# 1я трансформация - ужать до 224*224, 2я превратить изображение в тензор, 3я отнормировать изображения до тех параметнров, на изображениях с которыми ResNet был обучен изначально.\n",
        "\n",
        "batch_size = 18    # размер батча 8 картинок. батчи должны быть полными, т.е. кол-во элементов (в нашем случае 40) должно нацело делиться на кол-во элементов в батче\n",
        "train_dataloader = torch.utils.data.DataLoader(      # train_dataloader объект который отдает батчи с изображениями\n",
        "    train_dataset, batch_size=batch_size, shuffle=True, num_workers=batch_size)\n",
        "val_dataloader = torch.utils.data.DataLoader(\n",
        "    val_dataset, batch_size=batch_size, shuffle=False, num_workers=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "geFLb-5h8Hga"
      },
      "source": [
        "len(train_dataloader), len(train_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "gWP3MN2h8Hgc"
      },
      "source": [
        "len(val_dataloader), len(val_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "KfLrA3UC8Hge"
      },
      "source": [
        "# отобразим, что у нас в dataloader, при этом проделаем все трансформации в обратном порядке \n",
        "X_batch, y_batch = next(iter(train_dataloader))\n",
        "mean = np.array([0.485, 0.456, 0.406])\n",
        "std = np.array([0.229, 0.224, 0.225])\n",
        "plt.imshow(X_batch[0].permute(1, 2, 0).numpy() * std + mean);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Z8KdpWlh8Hgf"
      },
      "source": [
        "# функция, для отображения что у нас получается в трейновом dataloader\n",
        "def show_input(input_tensor, title=''):\n",
        "    image = input_tensor.permute(1, 2, 0).numpy()\n",
        "    image = std * image + mean\n",
        "    plt.imshow(image.clip(0, 1))\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "    plt.pause(0.001)\n",
        "\n",
        "X_batch, y_batch = next(iter(train_dataloader))\n",
        "\n",
        "for x_item, y_item in zip(X_batch, y_batch):\n",
        "    show_input(x_item, title=class_names[y_item])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "e9yYYu0T8Hgg"
      },
      "source": [
        "# тренировка Нейронной сети\n",
        "# 1. модель resnet18 (архитектура), 2. лосс ф-я nn.CrossEntropyLoss, 3. метод градиентного спуска Adam, 4. планировщик как будет уменьшаться шаг градиентного спуска\n",
        "model = models.resnet152(pretrained=True) #(include_top=False, classes=2, input_shape = (224,224,3))\n",
        "\n",
        "# изначально обученую сеть с 152ю слоями resnet152 мы \"заморозим\", т.е. не будем изменять\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# поменяем последний полносвязный слой, т.к. оригинальный resnet18 в конце разбивает изображения на 1000 классов, а у нас их 2 - чистые/грязные\n",
        "# model.fc.in_features - кол-во нейронов на вход, 2- кол-во нейронов на выход  - 2 класса\n",
        "model.fc = torch.nn.Linear(model.fc.in_features, 2)\n",
        "\n",
        "# перекладываем нашу сеть на gpu для ускорения процесса обработки данных\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# т.к. у нас 2 класса подойдет бинарная кросс-энтропия\n",
        "loss = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# метод градиентного спуска Adam\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)   #optim.Adam(model.parameters(), lr=1.0e-3)\n",
        "\n",
        "# с течением обучения нужно уменьшать шаг градиентного спуска\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "2I94j6pj8Hgh"
      },
      "source": [
        "# функция train_model каждую эпоху проходит по батчам. \n",
        "# если это обучение, то она делает степы (бэкворд+град спуск), если валидация - просто считаем качество, чтобы наблюдать не начали ли мы переобучаться\n",
        "\n",
        "def train_model(model, loss, optimizer, scheduler, num_epochs):\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}:'.format(epoch, num_epochs - 1), flush=True)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:  # фаза трейна \n",
        "            if phase == 'train':\n",
        "                dataloader = train_dataloader # dataloader дает батчи из трейнового датасета, т.е. из папки трейн\n",
        "                scheduler.step() # планировщик делает шаг, который говорит что произошла одна эпоха\n",
        "                model.train()  # перевод модели в фазу трейна. даже если мы не делаем бэкворд, даже если мы не считаем градиент и не изменяем веса, тем не менее в формард пассе у нас могут меняться параметры слоя батч-нормализации\n",
        "            else:\n",
        "                dataloader = val_dataloader\n",
        "                model.eval()   # перевод модели в фазу валидации. это важно (!), т.к. во время валидации НС может изменяться\n",
        "\n",
        "            running_loss = 0.\n",
        "            running_acc = 0.\n",
        "\n",
        "            # итерации по dataloader, он отдает батчи с одним тензором изображения и с одним тензором лейбла\n",
        "            for inputs, labels in tqdm(dataloader):\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad() # обнуляем градиент, чтобы он не накапливался\n",
        "\n",
        "                # forward and backward\n",
        "                with torch.set_grad_enabled(phase == 'train'): # обертка, которая активирует те градиенты, которые \"не заморожены\", это сильно ускоряет расчет\n",
        "                    preds = model(inputs) # inputs передаем в модель и считаем прогнозы, выходы это не вероятности, а некоторые активации нейронов\n",
        "                    loss_value = loss(preds, labels) # расчет лосс ф-ции\n",
        "                    preds_class = preds.argmax(dim=1) # прогноз класса,к которому относится наше изображение. берем argmax - нейрон с максимальной активацией\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss_value.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # расчет статистик. нужен для понимания уменьшается ли loss с течением эпох или вышел на платто\n",
        "                # нам нужны loss-ы и accuracy, т.к. єто метрика нашего соревнования и нужно понимать как она изменяется с течением эпох\n",
        "                running_loss += loss_value.item()\n",
        "                running_acc += (preds_class == labels.data).float().mean()\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloader) # усредняем, деля на кол-во батчей в эпохе, т.е. на len(dataloader)\n",
        "            epoch_acc = running_acc / len(dataloader)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc), flush=True)\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "mNE-mz488Hgi"
      },
      "source": [
        "# функция, которая получает на вход все аргументы (model, loss, optimizer, scheduler) + количество эпох (сколько мы хотим обычать нашу модель)\n",
        "train_model(model, loss, optimizer, scheduler, num_epochs=100);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "5M0wX3bj8Hgj"
      },
      "source": [
        "# переносим все тестовые изображения в папку test/unknown, т.к. ImageFolder при передаче каждого изображения привязывает лейбл(название корневой папки, ранее клин/дерти) и если не создать новую папку в папке, то ImageFolder-у негде будет брать лейбл\n",
        "# теперь у тестовых изображений будет лейбл unknown. неважно, как он будет называться, важно чтобы он был.\n",
        "test_dir = 'test'\n",
        "shutil.copytree(os.path.join(data_root, 'test'), os.path.join(test_dir, 'unknown'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "-vlojjG78Hgk"
      },
      "source": [
        "# мы не знаем какие названия/id-ишники генерируются у изображений, когда мы просим у DataLoader дать следующий батч.\n",
        "# поэтому нужно переписать ImageFolder, чтобы он отдавал не просто tuple с изображением и меткой, а еще чтобы давал имя или путь к изображению.\n",
        "# эту задачу решает __getitem__\n",
        "class ImageFolderWithPaths(torchvision.datasets.ImageFolder):\n",
        "    def __getitem__(self, index):\n",
        "        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n",
        "        path = self.imgs[index][0]\n",
        "        tuple_with_path = (original_tuple + (path,))\n",
        "        return tuple_with_path\n",
        "    \n",
        "test_dataset = ImageFolderWithPaths('/kaggle/working/test', val_transforms) # теперь test_dataset отдает tuple с 3мя значениями\n",
        "\n",
        "test_dataloader = torch.utils.data.DataLoader(\n",
        "    test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "JH-I7iSY8Hgm"
      },
      "source": [
        "test_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "cjDLyBRY8Hgm"
      },
      "source": [
        "# прогоним все изображения через сеть и получим прогнозы\n",
        "\n",
        "# переходим в модель eval, т.е. никаких изменений внутри происходить не будет, жестко зафиксированы все веса и параметры НС\n",
        "model.eval()\n",
        "\n",
        "# наполняем 2 списка - наши предсказания и пути к изображениям\n",
        "test_predictions = []\n",
        "test_img_paths = []\n",
        "for inputs, labels, paths in tqdm(test_dataloader):\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    with torch.set_grad_enabled(False):\n",
        "        preds = model(inputs)\n",
        "    test_predictions.append(\n",
        "        torch.nn.functional.softmax(preds, dim=1)[:,1].data.cpu().numpy()) #перегон прогнозов (подаются на вход) в вероятности первого класса (от 0 до 1)\n",
        "    test_img_paths.extend(paths)\n",
        "    \n",
        "test_predictions = np.concatenate(test_predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "PeH1Qn2b8Hgn"
      },
      "source": [
        "# вывод изображений тарелок с вероятностью что они \"грязные\"\n",
        "inputs, labels, paths = next(iter(test_dataloader))\n",
        "\n",
        "for img, pred in zip(inputs, test_predictions):\n",
        "    show_input(img, title=pred)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}